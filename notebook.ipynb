{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74de829b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kwon\\AppData\\Local\\Temp\\ipykernel_26188\\3851760724.py:29: LangChainDeprecationWarning: The class `UnstructuredFileLoader` was deprecated in LangChain 0.2.8 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-unstructured package and should be used instead. To use it run `pip install -U :class:`~langchain-unstructured` and import as `from :class:`~langchain_unstructured import UnstructuredLoader``.\n",
      "  loader = UnstructuredFileLoader(\"./files/chapter_three.txt\", mode=\"single\")\n",
      "libmagic is unavailable but assists in filetype detection. Please consider installing libmagic for better results.\n",
      "c:\\Users\\kwon\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr--P7Goz9u-py3.11\\Lib\\site-packages\\langchain\\embeddings\\cache.py:58: UserWarning: Using default key encoder: SHA-1 is *not* collision-resistant. While acceptable for most cache scenarios, a motivated attacker can craft two different payloads that map to the same cache key. If that risk matters in your environment, supply a stronger encoder (e.g. SHA-256 or BLAKE2) via the `key_encoder` argument. If you change the key encoder, consider also creating a new cache, to avoid (the potential for) collisions with existing keys.\n",
      "  _warn_about_sha1_encoder()\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain_community.document_loaders import UnstructuredFileLoader\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.embeddings import CacheBackedEmbeddings\n",
    "from langchain.storage import LocalFileStore\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough, RunnableLambda\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# 1) LLM\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    temperature=0.1,\n",
    ")\n",
    "\n",
    "memory = ConversationBufferMemory(\n",
    "    llm=llm,\n",
    "    return_messages=True,\n",
    ")\n",
    "\n",
    "# 2) 캐시 저장소\n",
    "cache_dir = LocalFileStore(\"./.cache/\")\n",
    "\n",
    "# 3) 텍스트 스플리터\n",
    "splitter = CharacterTextSplitter.from_tiktoken_encoder(\n",
    "    separator=\"\\n\",\n",
    "    chunk_size=600,\n",
    "    chunk_overlap=100,\n",
    ")\n",
    "\n",
    "# 4) 문서 로드\n",
    "loader = UnstructuredFileLoader(\"./files/chapter_three.txt\", mode=\"single\")\n",
    "docs = loader.load()\n",
    "splits = splitter.split_documents(docs)\n",
    "\n",
    "# 5) 임베딩 + 캐시\n",
    "embeddings = OpenAIEmbeddings()\n",
    "cached_embeddings = CacheBackedEmbeddings.from_bytes_store(embeddings, cache_dir)\n",
    "\n",
    "# 6) 벡터스토어 & 리트리버\n",
    "vectorstore = FAISS.from_documents(splits, cached_embeddings)\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 4})  \n",
    "\n",
    "# 7) 프롬프트\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a helpful assistant. Answer questions using only the following context. \"\n",
    "            \"If you don't know the answer just say you don't know, don't make it up:\\n\\n{context}\",\n",
    "        ),\n",
    "        (\"human\", \"{question}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 문서 리스트 → 문자열로 변환\n",
    "# def format_docs(docs):\n",
    "#     return \"\\n\\n\".join(d.page_content for d in docs)\n",
    "\n",
    "# 8) 체인 (문서 포맷팅 + 출력 파서 추가)\n",
    "\n",
    "chain = (\n",
    "    {\n",
    "    # | RunnableLambda(format_docs)\n",
    "        \"context\": retriever ,  # ← 핵심 수정\n",
    "        \"question\": RunnablePassthrough(),\n",
    "    }\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()  \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "36b190dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "According to the context, Winston believes that Aaronson, along with Jones and Rutherford, is guilty of the crimes they are charged with, even though he has never seen the photograph that disproved their guilt and acknowledges that it had never existed.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "result = chain.invoke(\"Is Aaronson guilty?\")\n",
    "print(result)  # ChatOpenAI의 반환은 Message이므로 .contentfrom langchain.memory import ConversationSummaryBufferMemory, ConversationBufferMemory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b83956",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = chain.invoke(\"Is Aaronson guilty?\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e5c9e873",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I don't know.\n"
     ]
    }
   ],
   "source": [
    "result = chain.invoke(\"What message did Aaronson write on the table?\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cd177d20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Julia is a character who is significant to the protagonist, Winston. She is someone he loves and has a deep emotional connection with, as indicated by Winston's overwhelming feelings for her during moments of reverie and distress.\n"
     ]
    }
   ],
   "source": [
    "result = chain.invoke(\"Who is Julia\")\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-kr--P7Goz9u-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
