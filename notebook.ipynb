{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "74de829b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='이 시는 파이썬이라는 프로그래밍 언어를 통해 전하는 이야기를 담고 있습니다. \\n\\n시인은 파이썬 코드를 통해 안식처와 같은 따뜻함을 느끼고, 문법의 우아함과 알고리즘의 아름다움으로 매료됩니다. 또한 코드 속에는 신비한 세계가 펼쳐지며 변수와 함수가 서로 속삭이며 상호작용합니다. 인터프리터는 마치 시인을 따라다니며 무한한 가능성을 보여줍니다.\\n\\n예외처리는 인생의 교훈처럼 오류를 극복하며 배우는 것으로 표현되고, 객체지향 프로그래밍에서 클래스가 만나는 순간은 신비로운 여정으로 묘사됩니다.\\n\\n시인은 파이썬의 강력함으로 자신의 믿음과 열정을 담아내며 코드를 통해 자신의 이야기를 전하고 세상에 디지털 시를 만들어나가겠다고 표현하고 있습니다. 이는 파이썬이라는 언어를 통해 자아를 표현하고 창의적으로 표현할 수 있는 프로그래밍의 아름다움을 감상할 수 있는 시입니다.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 390, 'prompt_tokens': 662, 'total_tokens': 1052, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-C0qSMrAk72xyqhtG0CNwn2wStfmEi', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='run--1dd378f0-7314-4cc3-940e-9bde2cb1cbd1-0' usage_metadata={'input_tokens': 662, 'output_tokens': 390, 'total_tokens': 1052, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "chat = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
    "\n",
    "# 첫 번째 체인: 언어를 받아 시를 만듦\n",
    "template_make = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"당신은 프로그래밍 언어를 가지고 훌륭한 시를 만드는 시인입니다. 서정적이면서도 아름다운 시를 만듭니다\"),\n",
    "    (\"user\", \"{language} 언어를 사용해서 프로그래밍 관련 시를 만들어주세요.\")\n",
    "])\n",
    "chain1 = template_make | chat\n",
    "\n",
    "rename_output = chain1 | RunnableLambda(lambda output: {\"poem\": output})\n",
    "\n",
    "# 두 번째 체인: 시를 받아 해석함\n",
    "template_trans = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"당신은 훌륭한 해석가입니다. 주어진 시를 가지고 논리적이고도 아름답게 해석을 합니다\"),\n",
    "    (\"user\", \"{poem} 시를 해석해주세요.\")\n",
    "])\n",
    "chain2 = template_trans | chat\n",
    "\n",
    "# 최종 체인\n",
    "final_chain = rename_output | chain2\n",
    "\n",
    "# 실행\n",
    "result = final_chain.invoke({\"language\": \"Python\"})\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-kr--P7Goz9u-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
